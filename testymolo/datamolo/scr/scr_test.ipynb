{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INSERTS:str = \"./../../testymolo/media/old_sql/VIRUS_1-2004-11-04_Inserts_2.sql\"\n",
    "TABLES: str = \"./../../testymolo/media/old_sql/VIRUS_1-2004-11-04_Tables.sql\"\n",
    "\n",
    "\n",
    "tables_csv: str = \"./../../testymolo/media/tables_csv/\"\n",
    "testydata: str = \"./../../testymolo/media/data/\"\n",
    "data_json: str = \"./../../testymolo/media/data/data.json\"\n",
    "multifasta: str = \"./../../testymolo/media/data/sequences.fasta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### caution when not all rows same nbr of col\n",
    "import re\n",
    "import os\n",
    "\n",
    "def custom_csv_parser_to_list(infilepath:str):\n",
    "    with open(infilepath ,'r') as handle:\n",
    "\n",
    "        rows:list = []\n",
    "\n",
    "        for line in handle.readlines():\n",
    "            line = line.strip(';') # removing terminal ';' \n",
    "            values:list = [] # re-initialize value list\n",
    "            val:str = \"\" # current parsing value\n",
    "            inquote:bool = False # re-initialize in quote : False\n",
    "            quote_char:str = '' # ' or \"\n",
    "            for c in line:\n",
    "                if(c == ','): # encounter comma\n",
    "                    if(not inquote): ## and not in quote\n",
    "                        val = val.strip(\"'\")\n",
    "                        val = val.strip('\"')\n",
    "                        if(len(val) > 0):\n",
    "                            values.append(val)\n",
    "                        else:\n",
    "                            values.append(None)\n",
    "                        val = \"\"\n",
    "                        continue\n",
    "                elif(c == '\"' or c == \"'\"): # encounter quote\n",
    "                    if(inquote): # already in quote \n",
    "                        if(quote_char == c):  # encounter ending quote mark\n",
    "                            inquote = False\n",
    "                        else: # encounter the other quote mark \n",
    "                            pass\n",
    "                    else: # encounter starting quote mark\n",
    "                        inquote = True\n",
    "                        quote_char = c\n",
    "                elif((c == ' ' or c == '\\n') and not inquote):  # get rid of whitespaces\n",
    "                    continue\n",
    "                val += c\n",
    "            if(len(val)>0):\n",
    "                val = val.strip(\"'\")\n",
    "                val = val.strip('\"')\n",
    "                values.append(val)\n",
    "\n",
    "            if(len(values) > 0):\n",
    "                rows.append(values)\n",
    "                #print(values)  \n",
    "        \n",
    "        print(\"nbr of col\", set([len(row) for row in rows]))\n",
    "        print(\"nbr of rows\", len(rows))\n",
    "        return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Organism\n",
    "Organism_h: list = [\"Tax_id\", \"Name\", \"Categorie\",\n",
    "                    \"Classe\", \"Ordre\", \"Fam\", \"SsFam\", \"Genre\", \"Note_org\"]\n",
    "Organism_p: str = os.path.join(tables_csv, 'Organism.csv')\n",
    "Organism: list = custom_csv_parser_to_list(Organism_p)\n",
    "print(Organism_h)\n",
    "print(Organism[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CAZy_DB\n",
    "CAZy_DB_h: list = [\"DB_ac\", \"Protein\", \"DB_nom\", \"Organism\", \"abr\", \"Tax_id\", \"EC\", \"_3D_status\",\n",
    "                   \"Length\", \"Sequence\", \"DB_note\", \"Created\", \"Modified\", \"PP_status\", \"Lib_sort\"]  # 15\n",
    "CAZy_DB_p: str = os.path.join(tables_csv, 'CAZy_DB.csv')\n",
    "\n",
    "CAZy_DB: list = custom_csv_parser_to_list(CAZy_DB_p)\n",
    "print(CAZy_DB[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test on bio.entrez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Entrez\n",
    "import json\n",
    "\n",
    "Entrez.email = \"VIMVer@univ-amu.fr\"\n",
    "\n",
    "def get_tax_data(taxid):\n",
    "    try:\n",
    "        search = Entrez.efetch(id=taxid, db='taxonomy', retmode='xml')\n",
    "        return Entrez.read(search)\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "def extract_TaxId(taxon):\n",
    "    return taxon['TaxId']\n",
    "\n",
    "def extract_Name(taxon):\n",
    "    return taxon['ScientificName']\n",
    "\n",
    "def extract_phylo(taxon):\n",
    "    return taxon['Lineage']\n",
    "\n",
    "for result in get_tax_data(\"11020\"):\n",
    "    taxon = {\n",
    "        'TaxId':extract_TaxId(result),\n",
    "        'Name':extract_Name(result),\n",
    "        'phylogeny':extract_phylo(result)\n",
    "        }\n",
    "    taxon_json = json.dumps(taxon)\n",
    "    print(taxon_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in get_tax_data(\"31631\"):\n",
    "    taxon = {\n",
    "        'TaxId':extract_TaxId(result),\n",
    "        'Name':extract_Name(result),\n",
    "        'phylogeny':extract_phylo(result)\n",
    "        }\n",
    "    taxon_json = json.dumps(taxon)\n",
    "    print(taxon_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Organism_json:str = \"\"\n",
    "\n",
    "with open(data_json, 'r') as handle:\n",
    "    DATA = json.load(handle)\n",
    "    for org in DATA:\n",
    "        results = []\n",
    "        n = 0\n",
    "        for result in get_tax_data(org):\n",
    "            taxon = {\n",
    "                'TaxId':extract_TaxId(result),\n",
    "                'Name':extract_Name(result),\n",
    "                'phylogeny':extract_phylo(result)\n",
    "                }\n",
    "            taxon_json = json.dumps(taxon)\n",
    "            results.append(taxon_json)\n",
    "            print(n, taxon_json)\n",
    "            n += 1\n",
    "        if(len(results) > 1):\n",
    "            input(f\"{org}: not found ! ([enter]: to continue)\")\n",
    "        elif(len(results) == 1):\n",
    "            ans = input(f\"{org}: only one found ([enter]: to continue or [else][enter]: to delete)\")\n",
    "            if(ans == \"\"):\n",
    "                Organism_json += \",\"+results[0]+\"\\n\"\n",
    "        else:\n",
    "            ans = int(input(\"which to keep ? ([index][enter]: to select)\"))\n",
    "            while(ans == \"\" or ans < 0 or ans > len(results)):\n",
    "                ans = input(\"plz choose between items above !\")\n",
    "            Organism_json += \",\"+results[ans]+\"\\n\"\n",
    "\n",
    "import os\n",
    "with open(os.path.join(testydata, 'Organism.json'), 'w') as outfile :\n",
    "    outfile.write('['+Organism_json[1:]+']')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merge old and new "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ToDoList:list = []\n",
    "DoneList:list = []\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "### INITIATLIZE ToDoList\n",
    "def initialize():\n",
    "    ToDoList_handler =  open(os.path.join(testydata, \"merge\", \"ToDoList\"), '+w')\n",
    "    DoneList_handler =  open(os.path.join(testydata, \"merge\", \"DoneList\"), 'a')\n",
    "    for item in CAZy_DB:\n",
    "        taxid = item[5]\n",
    "        if(not taxid in ToDoList):\n",
    "            ToDoList.append(taxid)\n",
    "    for org in Organism:\n",
    "        taxid = org[0]\n",
    "        if(not taxid in ToDoList):\n",
    "            ToDoList.append(taxid)\n",
    "    ToDoList_handler.write(\"\\n\".join(ToDoList))\n",
    "    ToDoList_handler.close()\n",
    "    DoneList_handler.close()\n",
    "\n",
    "def resume():\n",
    "    with open(os.path.join(testydata, \"merge\", \"ToDoList\"), '+r') as handle:\n",
    "        ToDoList:list = handle.readlines()\n",
    "\n",
    "        def extraction(taxid:str) -> list:\n",
    "            results:list = []\n",
    "            #1+\n",
    "            bio_entrez_result = get_tax_data(taxid)\n",
    "            results.append([record for record in bio_entrez_result])\n",
    "            #2 \n",
    "            results.append([org for org in Organism if int(org[0]) == int(taxid)])\n",
    "            #3+\n",
    "            results.append([item for item in CAZy_DB if int(item[5]) == int(taxid)])\n",
    "\n",
    "            return results\n",
    "                       \n",
    "        def get_TaxId(results:list) -> list:\n",
    "            #j = 0\n",
    "            #answers:list = []\n",
    "            #print(\"\\tBio.entrez\")\n",
    "            for record in results[0]:\n",
    "                #answers.append(record['TaxId'])\n",
    "                return record['TaxId']\n",
    "                print('\\t\\t', j, record['TaxId'])\n",
    "                j += 1\n",
    "            #print(\"\\tOrganism\")\n",
    "            #for org in results[1]:\n",
    "            #    answers.append(org[0])\n",
    "            #    print('\\t\\t', j, org[0])\n",
    "            #    j += 1\n",
    "            #cured_list:list = []\n",
    "            #print(\"\\tDB.ac\")\n",
    "            #for item in results[2]:\n",
    "            #    if not item[5] in cured_list:\n",
    "            #        cured_list.append(item[5])\n",
    "            #for item in cured_list:\n",
    "            #    answers.append(item)\n",
    "            #    print('\\t\\t', j, item)\n",
    "            #    j += 1\n",
    "            #return answers\n",
    "\n",
    "        def get_Name(results:list) -> list:\n",
    "            #j = 0\n",
    "            #answers:list = []\n",
    "            #print(\"\\tBio.entrez\")\n",
    "            for record in results[0]:\n",
    "            #    answers.append(record['ScientificName'])\n",
    "                return record['ScientificName']\n",
    "            #    print('\\t\\t', j, record['ScientificName'])\n",
    "            #    j += 1\n",
    "            #print(\"\\tOrganism\")\n",
    "            #for org in results[1]:\n",
    "            #    return org[1]\n",
    "            #    print('\\t\\t', j, org[1])\n",
    "            #    j += 1\n",
    "            #cured_list:list = []\n",
    "            #print(\"\\tDB.ac\")\n",
    "            #for item in results[2]:\n",
    "            #    if not item[3] in cured_list:\n",
    "            #        cured_list.append(item[3])\n",
    "            #for item in cured_list:\n",
    "            #    answers.append(item)\n",
    "            #    print('\\t\\t', j, item)\n",
    "            #    j += 1\n",
    "            #return answers\n",
    "\n",
    "        def get_Abr(results:list) -> list:\n",
    "            #j = 0\n",
    "            #answers:list = []\n",
    "            #print(\"\\tOrganism\")\n",
    "            #for org in results[1]:\n",
    "            #    answers.append(org[-1])\n",
    "            #    print('\\t\\t', j, org[-1])\n",
    "            #    j += 1\n",
    "            cured_list:list = []\n",
    "            #print(\"\\tDB.ac\")\n",
    "            for item in results[2]:\n",
    "                if not item[4] in cured_list:\n",
    "                    cured_list.append(item[4])\n",
    "            for item in cured_list:\n",
    "                return item\n",
    "            #    answers.append(item)\n",
    "            #    print('\\t\\t', j, item)\n",
    "            #    j += 1\n",
    "            #return answers\n",
    "            \n",
    "        def get_phylogeny(results:list) -> list:\n",
    "            #j = 0 \n",
    "            #answers:list = []\n",
    "            #print(\"\\tBio.entrez\")\n",
    "            for record in results[0]:\n",
    "                return record['Lineage']\n",
    "                answers.append(record['Lineage'])\n",
    "                print('\\t\\t', j, record['Lineage'])\n",
    "                j += 1\n",
    "            #print(\"\\tOrganism\")\n",
    "            #for org in results[1]:\n",
    "            #    a:str = \" ; \".join(org[2:-1])\n",
    "            #    answers.append(a)\n",
    "            #    print('\\t\\t', j, a)\n",
    "            #    j += 1\n",
    "            #return answers\n",
    "\n",
    "        ## question/answer \n",
    "        def choose(answers:list, key:str) -> str: \n",
    "            def is_all_equals(foo:list):\n",
    "                if len(foo) < 1 :\n",
    "                    return True\n",
    "                bar = str(foo[0])\n",
    "                for item in foo:\n",
    "                    if str(item) != bar:\n",
    "                        return False\n",
    "                return True\n",
    "            if is_all_equals(answers):\n",
    "                ans = input(f\"{key}: [enter]: to continue ; [+][enter]: to save progression\")\n",
    "                return answers[0]\n",
    "                #taxon[key] = answers[0]\n",
    "            else:\n",
    "                ans = input(f\"{key}: [index][enter] to select\")\n",
    "                if ans == '' :\n",
    "                    ans = 0\n",
    "                while( int(ans) < 0 or int(ans) >= len(answers)):\n",
    "                    ans = int(input(f\"{key}: plz select one above !\"))\n",
    "                    return answers[int(ans)]\n",
    "                    #taxon[key] = answers[j]\n",
    "\n",
    "\n",
    "        for taxid in ToDoList:\n",
    "            taxon:dict = {}\n",
    "            taxid:str.strip() = taxid\n",
    "            \n",
    "            results:list = extraction(taxid)\n",
    "            \n",
    "            ## choose id \n",
    "            #print(\"Choose id :\")\n",
    "            #answers:list = get_TaxId(results)\n",
    "            #taxon['TaxId'] = choose(answers,'TaxId')\n",
    "            taxon['TaxId'] = get_TaxId(results)\n",
    "\n",
    "            ## choose Name\n",
    "            #print(\"Choose Name :\")\n",
    "            #answers:list = get_Name(results)\n",
    "            #taxon['Name'] = choose(answers, 'Name')\n",
    "            taxon['Name'] = get_Name(results)\n",
    "\n",
    "            ## choose Abr\n",
    "            #print(\"Choose Abr :\")\n",
    "            #answers:list = get_Abr(results)\n",
    "            #taxon['abr'] = choose(answers, 'abr')\n",
    "            taxon['abr'] = get_Abr(results)\n",
    "\n",
    "            ## choose phylogeny\n",
    "            #print(\"Choose phylogeny :\")\n",
    "            #answers:list = get_phylogeny(results)\n",
    "            #taxon['phylogeny'] = choose(answers, 'phylogeny')\n",
    "            taxon['phylogeny'] = get_phylogeny(results)\n",
    "\n",
    "            ### finish taxon\n",
    "            # 1. delete taxon from todolist\n",
    "            #with open(os.path.join(testydata, \"merge\", \"ToDoList\"), '+w') as handle :\n",
    "                # if taxid is at index 0 ...\n",
    "            #    handle.write(\"\".join(ToDoList[1:]))\n",
    "            #copycat:list = [item for item in ToDoList if item.strip() != taxid.strip()]\n",
    "            #handle.write(\"\".join(copycat))\n",
    "            #   -> add into donelist            \n",
    "            with open(os.path.join(testydata, \"merge\", \"DoneList\"), '+a') as DoneList_handler:\n",
    "                DoneList = DoneList_handler.readlines()\n",
    "                if not taxid in DoneList :\n",
    "                    DoneList_handler.write(taxid)\n",
    "                #print(f\"Remaing:{len(copycat)}\\tDone:{len(DoneList)}\")\n",
    "\n",
    "            yield taxon\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize()\n",
    "resume()\n",
    "\n",
    "with open(os.path.join(testydata, 'Organism.json'), 'w') as outfile :\n",
    "\n",
    "    outfile.write(json.dumps(list(resume())))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TaxId': '11120', 'Name': 'Infectious bronchitis virus', 'abr': 'AIBV[Beaudette]', 'phylogeny': 'Viruses; Riboviria; Orthornavirae; Pisuviricota; Pisoniviricetes; Nidovirales; Cornidovirineae; Coronaviridae; Orthocoronavirinae; Gammacoronavirus; Igacovirus; Avian coronavirus'}\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "import numpy as np\n",
    "\n",
    "testydata: str = \"./../../testymolo/media/data/\"\n",
    "tree1:str = \"\"\n",
    "Organism:list = []\n",
    "\n",
    "forest  = np.zeros((8,8))\n",
    "\n",
    "with open(os.path.join(testydata, \"Organism.temp.json\")) as handle:\n",
    "    Organism:list = json.loads(handle.read())\n",
    "    print(Organism[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gimme(A:list, B:list) -> int:\n",
    "    # give count of differences between to phylogenic paths A and B\n",
    "    c:int = 0\n",
    "    a,b = 0,0\n",
    "    while(a < len(A) and b < len(B)):\n",
    "        if(A[a] != B[b]):\n",
    "            c += 1\n",
    "        a += 1\n",
    "        b += 1\n",
    "    return c\n",
    "            \n",
    "def cupid(people:list) -> list:\n",
    "    # people: list of ids\n",
    "    # found the closest couple within the list\n",
    "    # recursive: new people(list) n-1, couple formed\n",
    "    if(len(people) <= 2):\n",
    "        #end \n",
    "        #forme the last couple -> root\n",
    "        return [people[0], people[1]]\n",
    "    else:\n",
    "        #found couple\n",
    "        N:int = len(people)\n",
    "        # -> calc matrix of differences of remaining people\n",
    "        NEO:np.array = neo(np.zeros((N,N)))\n",
    "        # -> -> forme new couple of the lowest score \n",
    "        a,b = morpheus(NEO)\n",
    "        # -> -> -> new people with couple formed \n",
    "        remaining_people:list = []\n",
    "        for i in range(len(people)):\n",
    "            if not (i == a or i == b):\n",
    "                remaining_people.append(people[i])\n",
    "        remaining_people.append([people[a], people[b]])\n",
    "        print(people[a], people[b])\n",
    "        return cupid(remaining_people)\n",
    "\n",
    "def neo(forest:np.array) -> np.array:\n",
    "    for i in range(len(forest)):\n",
    "        for j in range(len(forest)):\n",
    "            if(i == j or forest[i][j] != 0):\n",
    "                # ignore diagonal \n",
    "                # if value already set (!=0)\n",
    "                continue\n",
    "            A = Organism[i]['phylogeny'].split(';')\n",
    "            A = [item.strip() for item in A]\n",
    "            B = Organism[j]['phylogeny'].split(';')\n",
    "            B = [item.strip() for item in B]\n",
    "            forest[i][j] = gimme(A,B)\n",
    "            forest[j][i] = gimme(A,B)\n",
    "    #print(forest)\n",
    "    return forest\n",
    "\n",
    "def commun_grounds(A:str, B:str) -> str:\n",
    "    A:list = [a.strip() for a in A.split(';')]\n",
    "    B:list = [b.strip() for b in B.split(';')]\n",
    "    AB:list = []\n",
    "    i,j = 0,0\n",
    "    while(A[i] == B[j]):\n",
    "        AB.append(A[i])\n",
    "        i += 1 \n",
    "        j += 1\n",
    "    return '; '.join(AB)\n",
    "\n",
    "def morpheus(neo:np.array) -> (int,int) :\n",
    "    # transfrom neo into smith (matrix diagonal)\n",
    "    smith = agent_smith(neo)\n",
    "    lowest = lowerdeck(smith)\n",
    "    indexes:tuple = firstOccur(smith, lowest)\n",
    "    print(lowest)\n",
    "    return indexes\n",
    "\n",
    "def agent_smith(neo:np.array) -> list:\n",
    "    N = len(neo)\n",
    "    smith = []\n",
    "    for k in range(1,N):\n",
    "        smith.append([])\n",
    "        for i in range(k):\n",
    "            smith[k-1].append(neo[k][i])\n",
    "    return smith\n",
    "\n",
    "def lowerdeck(smith:list) -> int:\n",
    "    lowest = 100\n",
    "    for i in range(len(smith)):\n",
    "        for j in range(len(smith[i])):\n",
    "            lowest = min(smith[i][j], lowest)\n",
    "    return lowest\n",
    "\n",
    "def firstOccur(Matrix, value) -> tuple:\n",
    "    for i in range(len(Matrix)):\n",
    "        for j in range(len(Matrix[i])):\n",
    "            if(Matrix[i][j] == value):\n",
    "                return (i,j)\n",
    "\n",
    "def rewind(people:list, tree:str=\"\") -> str:\n",
    "    if(len(people) < 1):\n",
    "        #if int\n",
    "        if isinstance(people[0], int):\n",
    "            work:str = Organism[people[0]]['abr'].replace(' ', '_')\n",
    "            return '(' + tree + ',' + work + ')'\n",
    "        #if list\n",
    "        elif isinstance(people[0], list):\n",
    "            return rewind(people(0), tree) + ',' + tree\n",
    "    else:\n",
    "        txt:str = \"(\"\n",
    "        for k in people:\n",
    "            if isinstance(k, int):\n",
    "                work:str = Organism[k]['abr'].replace(' ', '_')\n",
    "                txt += work\n",
    "            elif isinstance(k, list):\n",
    "                txt += rewind(k, tree)\n",
    "            txt += ','\n",
    "        tree = txt[:-1] + ')' + tree            \n",
    "        \n",
    "    return tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "5 1\n",
      "0.0\n",
      "7 2\n",
      "1.0\n",
      "4 3\n",
      "1.0\n",
      "[5, 1] 6\n",
      "1.0\n",
      "[4, 3] [7, 2]\n",
      "2.0\n",
      "[[5, 1], 6] 0\n",
      "forest: [[[4, 3], [7, 2]], [[[5, 1], 6], 0]]\n",
      "newick: (((TGV[Purdue],MHV[A59]),(SARS-TOR2,HCoV-229E)),(((PEDV_[CV777],BCoV-ENT),HCoV-OC43),AIBV[Beaudette]));\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "import numpy as np\n",
    "\n",
    "def main():\n",
    "    ## params\n",
    "    testydata: str = \"./../../testymolo/media/data/\"\n",
    "    Organism:list = [] \n",
    "    with open(os.path.join(testydata, \"Organism.temp.json\")) as handle:\n",
    "        Organism:list = json.loads(handle.read())\n",
    "    people:list = range(len(Organism))\n",
    "\n",
    "    #Matrix\n",
    "    n = len(Organism)\n",
    "    NEO = np.zeros((n,n))\n",
    "    NEO = neo(NEO)\n",
    "\n",
    "    #run cupid\n",
    "    forest:list = cupid(people)\n",
    "    print('forest:', forest)\n",
    "    \n",
    "    #reconstitute newick ###\n",
    "    newick:str = rewind(forest)+';'\n",
    "    print('newick:', newick)\n",
    "    pass\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEO [[0. 3. 2. 3. 3. 2. 3. 2.]\n",
      " [3. 0. 2. 1. 3. 2. 0. 1.]\n",
      " [2. 2. 0. 2. 1. 1. 2. 2.]\n",
      " [3. 1. 2. 0. 3. 2. 1. 1.]\n",
      " [3. 3. 1. 3. 0. 1. 3. 2.]\n",
      " [2. 2. 1. 2. 1. 0. 2. 2.]\n",
      " [3. 0. 2. 1. 3. 2. 0. 1.]\n",
      " [2. 1. 2. 1. 2. 2. 1. 0.]]\n",
      "SMITH\n",
      "[3.0]\n",
      "[2.0, 2.0]\n",
      "[3.0, 1.0, 2.0]\n",
      "[3.0, 3.0, 1.0, 3.0]\n",
      "[2.0, 2.0, 1.0, 2.0, 1.0]\n",
      "[3.0, 0.0, 2.0, 1.0, 3.0, 2.0]\n",
      "[2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "#with open(os.path.join(testydata, \"people.temp.csv\"), 'w') as handle:\n",
    "\n",
    "n = len(Organism)\n",
    "NEO = np.zeros((n,n))\n",
    "NEO = neo(NEO)\n",
    "print('NEO', NEO)\n",
    "\n",
    "SMITH = agent_smith(NEO)\n",
    "print('SMITH')\n",
    "for line in SMITH:\n",
    "    print(line)\n",
    "\n",
    "    #handle.write()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    }
   ],
   "source": [
    "lowest = np.min(SMITH)\n",
    "indexes = np.where(SMITH == lowest)\n",
    "print(*indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 AIBV[Beaudette] Viruses; Riboviria; Orthornavirae; Pisuviricota; Pisoniviricetes; Nidovirales; Cornidovirineae; Coronaviridae; Orthocoronavirinae; Gammacoronavirus; Igacovirus; Avian coronavirus\n",
      "1 BCoV-ENT Viruses; Riboviria; Orthornavirae; Pisuviricota; Pisoniviricetes; Nidovirales; Cornidovirineae; Coronaviridae; Orthocoronavirinae; Betacoronavirus; Embecovirus; Betacoronavirus 1\n",
      "2 HCoV-229E Viruses; Riboviria; Orthornavirae; Pisuviricota; Pisoniviricetes; Nidovirales; Cornidovirineae; Coronaviridae; Orthocoronavirinae; Alphacoronavirus; Duvinacovirus\n",
      "3 MHV[A59] Viruses; Riboviria; Orthornavirae; Pisuviricota; Pisoniviricetes; Nidovirales; Cornidovirineae; Coronaviridae; Orthocoronavirinae; Betacoronavirus; Embecovirus; Murine coronavirus\n",
      "4 TGV[Purdue] Viruses; Riboviria; Orthornavirae; Pisuviricota; Pisoniviricetes; Nidovirales; Cornidovirineae; Coronaviridae; Orthocoronavirinae; Alphacoronavirus; Tegacovirus; Alphacoronavirus 1\n",
      "5 PEDV [CV777] Viruses; Riboviria; Orthornavirae; Pisuviricota; Pisoniviricetes; Nidovirales; Cornidovirineae; Coronaviridae; Orthocoronavirinae; Alphacoronavirus; Pedacovirus\n",
      "6 HCoV-OC43 Viruses; Riboviria; Orthornavirae; Pisuviricota; Pisoniviricetes; Nidovirales; Cornidovirineae; Coronaviridae; Orthocoronavirinae; Betacoronavirus; Embecovirus; Betacoronavirus 1\n",
      "7 SARS-TOR2 Viruses; Riboviria; Orthornavirae; Pisuviricota; Pisoniviricetes; Nidovirales; Cornidovirineae; Coronaviridae; Orthocoronavirinae; Betacoronavirus; Sarbecovirus\n"
     ]
    }
   ],
   "source": [
    "people:list = [ item for item in Organism]\n",
    "i = 0\n",
    "for org in Organism:\n",
    "    print(str(i) , org['abr'], org['phylogeny'])\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
